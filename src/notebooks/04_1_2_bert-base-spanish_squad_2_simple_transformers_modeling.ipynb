{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Entrenamiento con Simple Transformers del model BERT",
   "id": "2209be4c53837b4c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Paso 1: Cargar datos en Google Colab",
   "id": "66f78a3b9df35bbf"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Paso 2: Instalar librer√≠as",
   "id": "1d75cf920abeb18"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "!pip install transformers evaluate torch --quiet\n",
    "!pip install simpletransformers transformers datasets huggingface_hub scikit-learn\n",
    "!pip install evaluate --quiet"
   ],
   "id": "c4fe7288016b0b1d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Paso 3: Cargar librer√≠as",
   "id": "62c7c7e47382766d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForQuestionAnswering\n",
    "import evaluate\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from simpletransformers.question_answering import QuestionAnsweringModel, QuestionAnsweringArgs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from google.colab import files"
   ],
   "id": "250093ac02bf1302"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import logging\n",
    "logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.ERROR)"
   ],
   "id": "32fb838b5c5bea80"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "print(\"GPU available:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU name:\", torch.cuda.get_device_name(0))"
   ],
   "id": "5680ff0c1ec2b312"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Paso 4: Cargar datos",
   "id": "7db15c832d85ba11"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import json\n",
    "\n",
    "with open(\"/content/qa_dataset_col_mex_news_squad2.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "print(f\"‚úÖ Loaded {len(dataset)} records successfully!\")"
   ],
   "id": "a8ea89b235ef968d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "dataset = dataset[\"data\"]",
   "id": "736767fa21654867"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# üîß 1Ô∏è‚É£ Flatten your dataset so each row has 'context' and 'qas'\n",
    "def flatten_squad(dataset):\n",
    "    new_data = []\n",
    "    for article in dataset:\n",
    "        for para in article[\"paragraphs\"]:\n",
    "            new_data.append({\n",
    "                \"context\": para[\"context\"],\n",
    "                \"qas\": para[\"qas\"]\n",
    "            })\n",
    "    return new_data\n",
    "\n",
    "flattened_data = flatten_squad(dataset)\n",
    "\n",
    "# üîß 2Ô∏è‚É£ Split into train and eval sets (70/30)\n",
    "train_data, eval_data = train_test_split(flattened_data, test_size=0.3, random_state=42)"
   ],
   "id": "19cae72da45da52f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(f\"‚úÖ Training samples: {len(train_data)}\")\n",
    "print(f\"‚úÖ Eval samples: {len(eval_data)}\")"
   ],
   "id": "2a61be1f8f4e833"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Paso 5: Definir hiperpar√°metros",
   "id": "7ea09c6d399e1dad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_args = QuestionAnsweringArgs()\n",
    "\n",
    "# Training behavior\n",
    "model_args.train_batch_size = 8\n",
    "model_args.eval_batch_size = 8\n",
    "model_args.num_train_epochs = 4\n",
    "model_args.learning_rate = 2e-5\n",
    "model_args.gradient_accumulation_steps = 1\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.evaluate_during_training = True\n",
    "model_args.evaluate_during_training_steps = 500\n",
    "model_args.save_eval_checkpoints = False\n",
    "model_args.save_model_every_epoch = False\n",
    "model_args.save_steps = -1\n",
    "model_args.best_model_dir = \"./outputs/best_model/\"\n",
    "model_args.output_dir = \"./outputs/\"\n",
    "\n",
    "# Optimization\n",
    "model_args.max_seq_length = 384\n",
    "model_args.doc_stride = 128\n",
    "model_args.warmup_ratio = 0.1\n",
    "model_args.max_answer_length = 30\n",
    "\n",
    "# Logging\n",
    "model_args.logging_steps = 100\n",
    "model_args.evaluate_during_training_verbose = True\n",
    "model_args.manual_seed = 42\n",
    "\n",
    "# Resource handling\n",
    "model_args.use_multiprocessing = False  # safer for notebooks\n",
    "model_args.fp16 = torch.cuda.is_available()  # use mixed precision if CUDA available"
   ],
   "id": "d7eba23510ae2b00"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Paso 6: Cargar el modelo",
   "id": "3daa0e8809603c08"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model_original = QuestionAnsweringModel(\n",
    "    model_type=\"bert\",\n",
    "    model_name=\"mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es\",  # BETO distilled\n",
    "    args=model_args,\n",
    "    use_cuda=torch.cuda.is_available()\n",
    ")"
   ],
   "id": "bf12bf8632845930"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "model = QuestionAnsweringModel(\n",
    "    model_type=\"bert\",\n",
    "    model_name=\"mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es\",  # BETO distilled\n",
    "    args=model_args,\n",
    "    use_cuda=torch.cuda.is_available()\n",
    ")"
   ],
   "id": "7d8035f05d9ad114"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Paso 7: Entrenamiento del modelo",
   "id": "aa6b1974297a336a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "model.train_model(train_data, eval_data=eval_data)",
   "id": "a1d1cd78dd95ddab"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Paso 8: Evaluaci√≥n de los resultados",
   "id": "4cade4fb1f581e45"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "result_original, texts_original = model_original.eval_model(eval_data)\n",
    "print(\"üìä Evaluation results:\")\n",
    "print(result_original)"
   ],
   "id": "7b19ef6adb90f652"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "result, texts = model.eval_model(eval_data)\n",
    "print(\"üìä Evaluation results:\")\n",
    "print(result)"
   ],
   "id": "10c67c7f75ae455a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "correct = result['correct']\n",
    "similar = result['similar']\n",
    "incorrect = result['incorrect']\n",
    "total = correct + similar + incorrect\n",
    "\n",
    "# 1Ô∏è‚É£ Exact Match Accuracy\n",
    "exact_match = correct / total\n",
    "\n",
    "# 2Ô∏è‚É£ Weighted Accuracy (partial credit for 'similar')\n",
    "weighted_accuracy = (correct + 0.5 * similar) / total\n",
    "\n",
    "# 3Ô∏è‚É£ F1 Score approximation\n",
    "TP = correct + 0.5 * similar\n",
    "FN = 0.5 * similar + incorrect\n",
    "# Assuming FP = 0 (as Simple Transformers counts predictions, not negatives)\n",
    "precision = TP / TP\n",
    "recall = TP / (TP + FN)\n",
    "f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Print results\n",
    "print(f\"Exact Match (EM): {exact_match:.4f} ‚Üí {exact_match*100:.2f}%\")\n",
    "print(f\"Weighted Accuracy: {weighted_accuracy:.4f} ‚Üí {weighted_accuracy*100:.2f}%\")\n",
    "print(f\"F1 Score: {f1_score:.4f} ‚Üí {f1_score*100:.2f}%\")"
   ],
   "id": "7981c8b7e491097d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Paso 9: Guardar los resultados",
   "id": "ecce034275986ca7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Folder to save\n",
    "local_path = \"./QA_model\"\n",
    "os.makedirs(local_path, exist_ok=True)\n",
    "\n",
    "# Save the Hugging Face model & tokenizer directly\n",
    "model.model.save_pretrained(local_path)       # Saves weights + config\n",
    "model.tokenizer.save_pretrained(local_path)   # Saves vocab + tokenizer config\n",
    "\n",
    "# Check files\n",
    "!ls -l ./QA_model"
   ],
   "id": "1179d0048a4bc319"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "shutil.make_archive(\"QA_model_bert\", 'zip', local_path)\n",
    "print(\"‚úÖ Zipped model\")\n",
    "!ls -lh QA_model.zip"
   ],
   "id": "81d9811781ee7cc8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "files.download(\"QA_model_bert.zip\")",
   "id": "958bc406e89d451d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "shutil.move(\"QA_model_bert.zip\", \"/content/drive/MyDrive/Thesis_QA_Optimization/Model\")"
   ],
   "id": "cdbed63318caf13b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Path to the folder containing the saved model\n",
    "model_path = \"./QA_model\"  # change if different\n",
    "\n",
    "# Reload the model\n",
    "my_model = QuestionAnsweringModel(\n",
    "    \"bert\",\n",
    "    model_path,\n",
    "    use_cuda=True  # set to False if no GPU\n",
    ")"
   ],
   "id": "5e91adaaaa9c186c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Context & question\n",
    "context = \"Ciudad de M√©xico. El capit√°n de la Secretar√≠a de Marina, Abraham Jerem√≠as P√©rez Ram√≠rez, fue hallado muerto en Tamaulipas.\"\n",
    "question = \"¬øQui√©n fue hallado muerto en Tamaulipas?\"\n",
    "\n",
    "# Prepare input in SimpleTransformers format\n",
    "to_predict = [\n",
    "    {\n",
    "        \"context\": context,\n",
    "        \"qas\": [\n",
    "            {\n",
    "                \"id\": \"0\",\n",
    "                \"question\": question,\n",
    "                \"answers\": [{\"text\": \" \", \"answer_start\": 0}],\n",
    "                \"is_impossible\": False\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Run prediction\n",
    "answers = my_model.predict(to_predict)\n",
    "print(answers)"
   ],
   "id": "b4a60fd09a01a6c1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
